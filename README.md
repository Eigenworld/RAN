we will upload the ipython file before 4-1-2022.



#  Irregular Message Passing Networks


### <p align="left"> Graph neural network (GNN) is a widely adopted technique to deal with graph-structured data. Despite its pervasiveness, the exact reasons for the message aggregatorâ€™s effectiveness are still poorly understood. The popular belief is that this effectiveness stems from optimizing edge weights to improve the local fusion of node information. In this work, we demonstrate that such propagation weight optimization has a limited contribution to the success of message passing. Instead, we find that any normalized random edge weights (or graph attentions) can have a similar and, sometime, even stronger effect. We refer to these randomly initialized propagations as irregular message passing. Experiments conducted on our random weight and random attention models verified the positive impact of weight randomness, uncovering the importance of the topology itself in achieving superior results for message iterations.</p>
